---
title: DPDK Overview
date: 2018-05-23 21:22:00
tags:
    - NUMA
    - Cache
    - DDIO
    - Ringbuffer
categories:
    - DPDK
---

## 为什么要使用 DPDK
网络刚开始时，只是在小范围内使用，并发量和响应时间要求并不高，而随着网络的普及，网络的范围越来越大，对服务器的并发量和响应时间要求越来越高，从而出现 C10k 问题。而现在 C10k 问题已经得到解决，又出现新的挑战，为了满足日益增长的需求主要采用分布式集群来分担负荷，应对大量的用户请求，对网络的要求也越来越高。

我们都知道网络的核心是报文转发，而传统的包转发需要走 Linux 的内核协议栈，这其中涉及到中断处理、系统调用、进程的上下文切换、从内核态到用户态的数据拷贝，这些都是不可避免的资源开销。加上控制面和数据面的数据并没有在转发平面得到分离，随着网络承载的通信量的持续增长和变化，大规模的网络数据包传输遇到瓶颈。
<!-- more -->
![](linuxstack.png)

数据面开发套件（DPDK， Data Plane Development Kit）是由 Intel 开源的用于快速数据包处理的函数库和驱动集合，其提供的用户态驱动能让应用程序绕过内核协议栈，直接接管网络数据包处理、内存管理以及CPU调度，可以极大的提高数据处理能力和吞吐量，提高数据面应用的工作效率。

![](dpdkstack.png)

## DPDK 组件

![](dpdkcomponents.png)

|库名               |描述|
|:-:                |:-:|
|librte_eal         |EAL,环境抽象层，指的是隐藏和系统相关的细节的通用上层面|
|librte_malloc      |rte_malloc() 是 malloc 的替代接口，用来从 DPDK 管理的巨页分配数据结构|
|librte_mempool     |内存管理：DPDK 的 pool 管理|
|librte_mbuf        |包缓存实现|
|librte_ring        |高效循环队列用于核间或进程间的包指针传递|
|librte_timer       |时钟管理|
|librte_lpm         |加速的最长匹配|
|librte_hash        |用于元组匹配的哈希驱动关键字值精确匹配|
|librte_acl         |一种访问控制链表的加速实现|
|librte_meter       |Meter/mark lib: Implements srTCM(RFC 2697) and trTCM(RFC 2698)|
|librte_sched       |软件层的流量整形器|
|librte_pmd*        |获取包的轮训模式驱动|
|librte_ether       |通用以太网设备抽象—— the DPDK PMD API|
|librte_cmdline     |命令行解析|
|librte_distributor |工作队列分配器|
|librte_power       |电源管理|
|librte_ivshmen     |共享内存实现的一种虚拟机之间通信方式|
|KNI,librte_kni     |内核网络接口——实现一种内核网络设备用于将包从 DPDK 转给内核|

## DPDK 核心概念

#### NUMA 系统
传统的计算机架构 SMP(Symetric Multiple Processing, 对称多处理器) 都有两个标准部分，南桥和北桥，他们是处理器和内存和其它外设沟通的桥梁。处理器和内存之间通过前端总线（FSB）相连。由图可知，处理器访问内存和外设都需要通过北桥，所以系统的瓶颈就在北桥，当北桥出现堵塞，那么所有的处理器和外设都要瘫痪。 NUMA（Non-Uniform Memory Architecture, 非一致性内存架构）系统是从 SMP 演变来的，这种架构通过将内存划分为处理器的本地内存和远程内存，将内存访问带宽直接增大了 4 倍。但是内存访问速度受到处理器和内存之间的“距离”的影响，简而言之就是访问本地内存总是快于访问远端内存，所以编程时尽量使用本地内存可提高程序的执行效率。
![](numa.png)

#### Cache 预取
>Cache 之所以能够提高系统性能，主要是程序执行存在局部性现象，即时间局部性和空间局部性。
>1）时间局部性：是指程序即将用到的指令/数据可能就是目前正在使用的指令/数据。因此，当前用到的指令/数据在使用完毕之后可以暂时存放在 Cache 中，可以在将来的时候再被处理器用到。一个简单的例子就是一个循环语句的指令，当循环终止的条件满足之前，处理器需要反复执行循环语句中的指令。
>2）空间局部性：是指程序即将用到的指令/数据可能与目前正在使用的指令/数据在空间上相邻或者相近。因此，在处理器处理当前指令/数据时，可以从内存中把相邻区域的指令/数据读取到 Cache 中，这样，当处理器需要处理相邻内存区域的指令/数据时，可以直接从 Cache 中读取，节省访问内存的时间。一个简单的例子就是二位数组的遍历问题。
>所谓的 Cache 预取，也就是预测数据并取入到 Cache 中，是根据空间局部性和时间局部性，以及当前执行状态、历史执行过程、软件提示等信息，然后以一定的合理方法，在数据/指令被使用前取入 Cache。这样，当数据/指令需要被使用时，就能快速从 Cache 中加载到处理器内部进行运算和执行。

#### TLB 和 Hugepage
TLB ( Translation Look-aside Buffer), 是专门用于缓存内存中的页表项而用的一种 Cache 。TLB 一般采用相连存储器或者按内容访问存储器，使用虚拟地址进行搜索，直接返回对应的物理地址，相对于内存中的多级页表需要多次访问才能得到最终的物理内存来说，无疑大大减少了内存访问的处理器开销。但是效率高的前提是要 Cache 命中，如果不命中，则采用多级页表方式获取物理地址。所以 DPDK 还引入了 Hugepage (大页)技术，通过增大每个页的大小，减少页表项，从而减少甚至规避 TLB 不命中的情况。

#### Intel DDIO(Data Direct I/O)
传统的网络报文处理，网卡需要将报文拷贝到内存，然后 CPU 从内存读取数据到 Cache, 处理之后再回写 Cache, 并最终返回到内存中。最后，网卡再读取内存中的数据，发送到外部网络。Intel DDIO 技术使外部网卡的和 CPU 通过 LLC Cache 直接交换数据，绕过了内存这个相对慢速的部件，从而增加 CPU 处理网络报文的速度（减少了 CPU 和网卡的等待时间）。
![](ddio.png)

#### DPDK 轮询模式
传统的内核态网卡驱动采用的是异步中断模式，即通过收包产生硬件中断，进而触发 CPU 中断，从而进入中断处理服务，完成收包。这期间需要不断的进行中断处理和上下文切换，这些处理带来的固定的 CPU 开销，从而降低了 CPU 的包处理能力。发包的过程与收包类似，因为是异步处理，因此 CPU 无需阻塞等待，有效利用率比较高。
DPDK 采用轮询或者轮询混合中断的模式来进行收发包。轮询模式是指收发完全不依赖任何中断，采用主动轮询的方式，检查网卡状态。对于收包队列， DPDK 都会有对应的一个线程负责轮询收包描述符，一旦发现有包进入网卡，驱动程序就会自动解析相应的收包描述符，并提取有用的信息填充到对应的缓冲内存头部，然后把收报缓冲内存块放到收包函数提供的数组里面，同时分配好一个新的缓冲块供下一个报文使用。发包类似，每个发包队列，DPDK 也有一个独立的线程负责设置需要发送的报文。
轮询混合中断模式即在开始收包时采用轮询模式，当发现一段时间轮询的报文都为零时，切换回中断模式。当下一个报文到达是，产生收包中断，唤醒收包线程，这个时候收包线程会关闭中断，重新开始轮询收包。

#### DPDK Ring (无锁环形缓冲队列)
......
